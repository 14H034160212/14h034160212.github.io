
<!DOCTYPE html>
<html>
<head>
    <title>Qiming Bao's Homepage</title>
    <link rel="icon" type="image/jpeg" href="./qiming.jpg">
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 0; }
        .container { width: 80%; margin: 0 auto; }
		.location{
		  float:right;
		  font-size: 10pt;
		  color: #000;
		}
		.date {
		  font-family: 'Open Sans', sans-serif;
		  float:right;
		  font-size: 10pt;
		  color:#878787;
		}
		.section_sub{
		  margin-bottom:10px;
		}
		.activity_header {
		  font-family: 'Open Sans', sans-serif;
		  color: #666;
		}
		 .header-left {
		  width: 36%;
		  float:left;
		}
		.header-right {
		  width: 42%;
		  float:right;
		  text-align: right;
		}
		.header-center {
		  width: 22%;
		  float:right;
		}
		.small-caps {
		  font-variant: small-caps;
		}
		.activity_header strong {
		  font-family: 'Open Sans', sans-serif;
		  font-size: 12pt;
		  /*font-weight: 600;*/
		  color: #000; /*#761F1F;*/
		}
		.activity_header stronger {
		  font-family: 'Open Sans', sans-serif;
		  font-size: 14pt;
		  /*font-weight: 600;*/
		  color: #000; /*#761F1F;*/
		}
		.activity_header_sub {
		  font-size: 10pt;
		}
        header { background-color: #f1f1f1; padding: 20px; text-align: center; }
        section { margin: 20px 0; }
        h2 { color: #333; }
        ul { list-style-type: none; padding: 0; }
        li { margin-bottom: 10px; }
    </style>
</head>
<body>
    <header>
        <h1>Qiming Bao</h1>
        <p>Ph.D. Candidate in Strong AI Lab, NAOInstitute, University of Auckland</p>
		<a href="https://profiles.auckland.ac.nz/qiming-bao" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-Homepage-purple?style=flat-square&logo=homepage&logoColor=white" alt="Homepage">
		</a>&nbsp;&nbsp;
		
		<a href="https://www.linkedin.com/in/qiming-bill-bao-773757166/" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white" alt="LinkedIn">
		</a>&nbsp;&nbsp;
		
		<a href="https://github.com/14H034160212" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-GitHub-black?style=flat-square&logo=GitHub&logoColor=white" alt="GitHub">
		</a>&nbsp;&nbsp;

		<a href="mailto:qbao775@aucklanduni.ac.nz" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-Gmail-red?style=flat-square&logo=Gmail&logoColor=white" alt="Gmail">
		</a>&nbsp;&nbsp;

		<a href="https://scholar.google.com/citations?user=t-PqsgcAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-Google%20Scholar-blue?style=flat-square&logo=Google%20Scholar&logoColor=white" alt="Google Scholar">
		</a>&nbsp;&nbsp;
		
		<a href="https://dblp.org/pid/126/9037-1.html" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-DBLP-yellow?style=flat-square&logo=DBLP&logoColor=white" alt="DBLP">
		</a>&nbsp;&nbsp;

		<a href="https://twitter.com/qiming_bao" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-Twitter-blue?style=flat-square&logo=Twitter&logoColor=white" alt="Twitter">
		</a>&nbsp;&nbsp;
		
		<a href="https://14h034160212.github.io/cv.html" target="_blank" style="text-decoration: none;">
			<img src="https://img.shields.io/badge/-CV-brown?style=flat-square&logo=CV&logoColor=white" alt="CV">
		</a>
    </header>
    <div class="container">
		<section>
            <h2>Personal Details</h2>
            <ul>
                Qiming Bao is a Ph.D. Candidate at the <A href="https://www.ai.ac.nz/sail/"><FONT face="Bitstream Vera Sans">Strong AI Lab</FONT></A>, <A href="https://www.naoinstitute.auckland.ac.nz/"><FONT face="Bitstream Vera Sans">NAOInstitute</FONT></A>, University of Auckland, New Zealand, supervised by Professor <A href="https://profiles.auckland.ac.nz/m-witbrock"><FONT face="Bitstream Vera Sans">Michael Witbrock</FONT></A>. His research interests include natural language processing and reasoning. He has over three years of research and development experience, and has published several papers in top conferences in the fields of AI/NLP/Reasoning, including <B>AAAI/EAAI</B>, <B>ICLR</B>, <B>ACL</B>, <B>EACL</B>, <B>LLM@IJCAI</B>, and <B>IJCLR-NeSy</B>. His method named <B>AMR-LDA</B> (GPT-4 + AMR-LDA Prompt Augmentation) has achieved the <B>#1</B> ranking on a one of the most challenged logical reasoning reading comprehension leaderboards (<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">ReClor</FONT></A>) up to now, and two of his logical reasoning datasets called <A href="https://github.com/Strong-AI-Lab/PARARULE-Plus"><FONT face="Bitstream Vera Sans">PARARULE-Plus</FONT></A> and <A href="https://github.com/Strong-AI-Lab/AbductionRules"><FONT face="Bitstream Vera Sans">AbductionRules</FONT></A> have been collected by <A href="https://www.logitorch.ai/"><FONT face="Bitstream Vera Sans">LogiTorch</FONT></A>, <A href="https://github.com/FreedomIntelligence/ReasoningNLP"><FONT face="Bitstream Vera Sans">ReasoningNLP</FONT></A>, <A href="https://github.com/zjunlp/Prompt4ReasoningPapers"><FONT face="Bitstream Vera Sans">Prompt4ReasoningPapers</FONT></A> and <A href="https://github.com/openai/evals/pull/651"><FONT face="Bitstream Vera Sans">OpenAI/Evals</FONT></A>. Qiming has given public guest talks at <A href="https://youtu.be/nfNbSZPY4EU"><FONT face="Bitstream Vera Sans">Microsoft Research Asia</FONT></A>, <A href="https://youtu.be/0ZkayBD3WVY"><FONT face="Bitstream Vera Sans">Samsung AI Center Cambridge UK</FONT></A>, <A href="https://youtu.be/ZzCpq5gXQto"><FONT face="Bitstream Vera Sans">IEEE Vehicular Technology Society</FONT></A>, <A href="https://14h034160212.github.io/Invitation_UoM_NLP_Reading_Group.pdf"><FONT face="Bitstream Vera Sans">The University of Melbourne</FONT></A> and <A href="https://14h034160212.github.io/包启明-中国科学院自动化所“第一届紫东青年学者论坛分论坛：AI基础理论与创新应用”.pdf"><FONT face="Bitstream Vera Sans">Institute of Automation, Chinese Academy of Sciences</FONT></A> on his main research topic, "Natural Language Processing and Reasoning".
				<br /><br />
				Qiming is an AI engineer (Part-time) at <A href="https://xtracta.com/"><FONT face="Bitstream Vera Sans">Xtracta</FONT></A> in Auckland, New Zealand, where he investigated and implemented alternative attention mechanisms to extend the effective sequence length in multi-modal document processing models such as LayoutLMv3 and ERNIE-LayoutX. He replicated the multi-task, multimodal pre-training code for LayoutLMv3, which Microsoft did not open source, including masked language modeling, masked image modeling, and word-patch alignment. He integrated DeepSpeed and adapters into ERNIE-LayoutX and LayoutLMv3, which can reduce training costs, result in a smaller model size, and make it easier to deploy in the production environment. He successfully applied for the Research & Development Tax Incentive (RDTI) grants from Callaghan Innovation (New Zealand's Innovation Agency) for both 2022 and 2023, each offering a tax credit equal to 15% of eligible R&D expenditure. This credit can be utilised to reduce the income tax payable by the company. Prior to this role, he worked as a research and development engineer in <A href="https://www.aiit.org.cn/p_enPage"><FONT face="Bitstream Vera Sans">AIIT</FONT></A> at Peking University, where he focused on automatic abstract generation and GPT-2 based dialog chatbot development. Qiming also has a great deal of teaching experience, having worked as a teaching assistant for three years. He earned a Bachelor of Science (Honours) in Computer Science (First Class) from the University of Auckland and completed a Summer Research Internship with Scholarship in <A href="https://precisiondrivenhealth.com/"><FONT face="Bitstream Vera Sans">Precision Driven Health</FONT></A>. In addition, he was selected as one of ten students to participate in the <A href="https://precisiondrivenhealth.com/an-online-system-for-answering-medical-questions/"><FONT face="Bitstream Vera Sans">Summer Research Program</FONT></A> funded by Precision Driven Health, where the main topic was developing a Medical Chatbot based on Deep Learning and Knowledge Graph.
            </ul>
        </section>
        <section>
            <h2>Education</h2>
			<li>Ph.D. in Computer Science, University of Auckland (2020 - Present)</li>
			<li>B.Sc. (Honours) in Computer Science (First Class), University of Auckland (2018 - 2019)</li>
			<li>B.Sc. in Computer Science, Auckland University of Technology (2016 - 2018)</li>
			<li>B.Sc. in Computer Science, China Jiliang University (2014 - 2018)</li>
            
        </section>
        <section>
            <h2>Research Interests</h2>
            <p>AI/DL, NLP, LLMs, Neural-Symbolic AI, Reasoning, Multimodal ML</p>
        </section>
        <section>
            <h2>Publications</h2>
            
			<!--<li><u>Qiming Bao</u>, Juho Leinonen, Alex Yuxuan Peng, Wanjun Zhong, Tim Pistotti, Alice Huang, Paul Denny, Michael Witbrock and Jiamou Liu) <em>Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models</em>, <b>arXiv preprint arXiv:2309.1044 (2023)</b></li>-->
			<li><u>Qiming Bao</u>, Gaël Gendron, Alex Peng, Neset Tan, Michael Witbrock, Jiamou Liu. <em>A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks.</em>, <b>LLM@IJCAI (2023)</b></li>
			<li><u>Qiming Bao</u>, Alex Peng, Zhenyun Deng, Wanjun Zhong, Gaël Gendron, Neşet Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock and Jiamou Liu. <em>Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation.</em>, <b>LLM@IJCAI (2023)</b></li>
			<!--<li><u>Qiming Bao</u>, Alex Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock, Jiamou Liu. <em>Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text.</em>, <b>arXiv preprint arXiv:2305.12599 (2023)</b></li>-->
			<li><u>Qiming Bao</u>, Alex Peng, Tim Hartill, Neset Tan, Zhenyun Deng, Michael Witbrock, Jiamou Liu. <em>Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation</em>, <b>IJCLR-NeSy (2022)</b></li>
			<li>Nathan Young, <u>Qiming Bao</u>, Joshua Ljudo Bensemann, Michael J. Witbrock. <em>AbductionRules: Training Transformers to Explain Unexpected Inputs</em>, <b>The Findings of ACL (2022)</b></li>
			<li>Lin Ni, <u>Qiming Bao</u>, Xiaoxuan Li, Qianqian Qi, Paul Denny, Jim Warren, Michael Witbrock, Jiamou Liu. <em>DeepQR: Neural-based Quality Ratings for Learnersourced Multiple-Choice Questions</em>, <b>AAAI/EAAI (2022)</b></li>
			<li>Qianqian Qi, <u>Qiming Bao</u>*, Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock. <em>A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge</em>, <b>ICLR TinyPapers (2023)</b></li>
			<!--<li>Gaël Gendron, <u>Qiming Bao</u>, Michael Witbrock, Gillian Dobbie. <em>Large Language Models Are Not Abstract Reasoners.</em>, <b>arXiv preprint arXiv:2305.19555 (2023)</b></li>-->
			<li><u>Qiming Bao</u>, Lin Ni, Jiamou Liu. <em>HHH: An Online Medical Chatbot System based on Knowledge Graph and Hierarchical Bi-Directional Attention</em>, <b>ACSW (2020)</b></li>
			<!--<li>Joshua Bensemann, <u>Qiming Bao</u>, Gaël Gendron, Tim Hartill, Michael Witbrock. <em>Relating Blindsight and AI: A Review</em>, <b>Journal of Artificial Intelligence and Consciousness (2021)</b></li>-->
			<!--<li><u>Qiming Bao</u>, Michael Witbrock, Jiamou Liu. <em>From Symbolic Logic Reasoning to Soft Reasoning: A Neural-Symbolic Paradigm</em>, <b>NZAIR (2021) Workshop Poster</b></li>-->
			<li>Zhongsheng Wang, Jiamou Liu, <u>Qiming Bao</u>, Hongfei Rong, Jingfeng Zhang. <em>ChatLogic: Integrating Logic Programming with Large Language Models for Multi-step Reasoning</em>, <b>NucLeaR@AAAI (2024)</b></li>
			<li>Neset TAN, Trung Nguyen, Josh Bensemann, Alex Peng, <u>Qiming Bao</u>, Yang Chen, Mark Gahegan, Michael Witbrock. <em>Multi2Claim: Generating Scientific Claims from Multi-Choice Questions for Scientific Fact-Checking</em>, <b>EACL (2023)</b></li>
			<li>Neset TAN, Alex Peng, Joshua Bensemann, <u>Qiming Bao</u>, Tim Hartill, Mark Gahegan, Michael Witbrock. <em>Input-length-shortening and text generation via attention values</em>, <b>AAAI-EMC^2 (2023)</b></li>

        </section>
		<section>
            <h2>Work & Project Experience</h2>
                <div class="section_sub">
					<span class="activity_header"><strong>Large Language Model and Logical Reasoning (Ph.D. Main Topic)</strong></span> <span class="location">UoA, Auckland, New Zealand</span><br />
					<span class="activity_header activity_header_sub">Research & Development Project Leader/Developer</span> <span class="date">02/20 &ndash; Now</span>
					
					<li>We have developed a self-reinforcement framework based on LLM for generating explanations. The framework iteratively interacts between an explanation generation module and an explanation evaluation module to enhance the quality of the generated explanations. <a href="http://arxiv.org/abs/2309.10444">paper</a> and <a href="https://github.com/Strong-AI-Lab/Explanation-Generation">source code</a>.</li>
					<li>Our method "AMR-LDA" (GPT-4 + AMR-LDA Prompt Augmentation) achieved #1 on the <a href="https://eval.ai/challenge/503/leaderboard/1347">ReClor leaderboard</a>, <a href="https://arxiv.org/abs/2305.12599v2">paper</a>, <a href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning">source code</a> and <a href="https://huggingface.co/qbao775/AMR-LE-DeBERTa-V2-XXLarge-Contraposition">model weights</a>. Our paper has been accepted by LLM@IJCAI'23.</li>
					<li>We evaluated generative and discriminative large language models on out-of-distribution logical reasoning tasks. While they excel in standard tasks, minor changes lead to notable performance drops, indicating insufficient reasoning capabilities. Our paper has been accepted by LLM@IJCAI'23. <a href="http://arxiv.org/abs/2310.09430">paper</a> and <a href="https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning">source code</a>.</li>
					<li>To address depth imbalance in multi-step reasoning datasets and enhance model performance, we created the IMA-GloVe-GA model, combining DeepLogic with Gate Attention. Additionally, we developed a larger dataset, PARARULE-Plus, for deep multi-step reasoning over natural language. We published the <a href="https://ceur-ws.org/Vol-3212/paper15.pdf">paper</a>, <a href="https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language">code and data</a> and <a href="http://ilp.doc.ic.ac.uk/ijclr22_videos/NeSy%20Session%205%20-%20Thursday%2029th%20-%2014_40%20-%2015_50%20(BST)%20includes%20NeSy%20Invited%20Talk%20William%20Cohen.mp4">presentation recording</a> on IJCLR-NeSy-22.</li>
					<li>We built up a dataset called AbductionRules to increase the Transformer's performance on the tasks requiring abduction reasoning. We published the <a href="https://aclanthology.org/2022.findings-acl.19/">paper</a>, <a href="https://github.com/Strong-AI-Lab/AbductionRules">code and data</a> on the Findings of ACL-22.</li>
					<li>PARARULE Plus (Multi-step deductive reasoning) and AbductionRules (Abductive reasoning) datasets are collected and merged as part of <a href="https://www.logitorch.ai/">LogiTorch.ai</a>, <a href="https://github.com/FreedomIntelligence/ReasoningNLP">ReasoningNLP</a>, <a href="https://github.com/zjunlp/Prompt4ReasoningPapers">Prompt4ReasoningPapers</a> and <a href="https://github.com/openai/evals/pull/651">OpenAI/Evals</a>.</li>	
					<!--<li>We developed a model called IMA-GloVe-GA, which is based on DeepLogic and Gate Attention. It performs better performance than other RNN-based models. We published the <a href="https://www.researchgate.net/profile/Qiming-Bao/publication/356695884_From_Symbolic_Logic_Reasoning_to_Soft_Reasoning_A_Neural-Symbolic_Paradigm/links/61a80a2229948f41dbb98913/From-Symbolic-Logic-Reasoning-to-Soft-Reasoning-A-Neural-Symbolic-Paradigm.pdf">poster</a> and <a href="https://github.com/Strong-AI-Lab/A-Neural-Symbolic-Paradigm">code</a> on NZAIR-21.</li>-->
					
				</div>
				
				<div class="section_sub">
					<span class="activity_header"><strong>Enhancing Max Sequence Length in Large Multimodal Models</strong></span> <span class="location">Xtracta, Auckland, New Zealand</span><br />
					<span class="activity_header activity_header_sub">Artificial Intelligence Researcher/Engineer</span> <span class="date">07/22 &ndash; now</span>
					<li>Investigate and implement alternative attention mechanisms to extend the effective sequence length in multi-modal document processing models such as LayoutLMv3 and ERNIE-LayoutX.</li>
					<li>By applying the sliding window technique and a global attention mask from Longformer to extend the maximum sequence length from 512 to 4096, which model among LayoutLMv3 and ERNIE-LayoutX achieves a higher F1 score on the XFUND, FUNSD and other company internal datasets without significantly increasing GPU memory usage.</li>
					<li>Replicate the multi-task, multimodal pre-training code for LayoutLMv3, which Microsoft did not open source, including masked language modeling, masked image modeling, and word-patch alignment.</li>	
					<li>Integrating deepspeed and adapters into ERNIE-LayoutX and LayoutLMv3, which can reduce training costs, result in a smaller model size, and make it easier to deploy in the production environment.</li>
					<li>Successfully applied for the Research & Development Tax Incentive (RDTI) grants from Callaghan Innovation (New Zealand's Innovation Agency) for both 2022 and 2023, each offering a tax credit equal to 15% of eligible R&D expenditure. This credit can be utilised to reduce the income tax payable by the company.</li>
				</div>

                <div class="section_sub">
					<span class="activity_header"><strong>Abstract Extraction and Multi-Turn Dialogue System</strong></span> <span class="location">Advanced Institute of Information Technology, Peking University, Hangzhou, China</span><br />
					<span class="activity_header activity_header_sub">Research and Development Engineer</span> <span class="date">11/19 &ndash; 02/20</span>
					
					<li>We developed and researched a robot-based system including automatic abstract extraction, text segmentation, theme prediction, and multi-turn question answering. <!--<a href="https://14h03
					60212.github.io/portofolio/aiit/index.html">Demo link</a>.--></li>
					<li>Investigation and standard documentation of robot-related technologies.</li>
					<li>We built a well-encapsulated API to implement meeting record document processing based on the abstract extraction, text segmentation, and theme prediction.</li>
					</div>
					<div class="section_sub">
					<span class="activity_header"><strong>HHH: An Online Medical Chatbot System </strong></span> <span class="location">Precision Driven Health, Auckland, New Zealand</span><br />
					<span class="activity_header activity_header_sub">Research Project Leader and Developer</span> <span class="date">11/18 &ndash; 04/19</span>
					
					<li>We developed a medical text similarity algorithm called HBAM using Deep Learning and Knowledge Graph.</li>
					<li>Compared with BERT and MaLSTM models, HBAM performs higher test accuracy than the two Deep Learning models respectively <a href="https://github.com/14H034160212/HHH-An-Online-Question-Answering-System-for-Medical-Questions">code (#star: 75+)</a>, <a href="https://www.linkedin.com/feed/update/urn:li:activity:6557064938186244096/">news</a>, <a href="https://youtu.be/zTK3zZtxHs4">recording</a> and <a href="https://arxiv.org/abs/2002.03140">published paper (#citation: 45+)</a> on ACSW-20.</li>
				</div>
        </section>
		<section>
			<h2>Invited Speaker</h2>
			<li>Microsoft Research Asia Invited Talk 2022 (<A href="https://14h034160212.github.io/Invited_Letter_for_MSRA_Group.pdf">Invitation Letter</A>) <A href="https://14h034160212.github.io/Presentation_Slide_MSRA_Group.pdf">(Presentation Slide)</A> (<A href="https://youtu.be/nfNbSZPY4EU">Recording</A>)</li>
			<li>Samsung AI Center Cambridge UK Invited Talk 2022 <A href="https://14h034160212.github.io/Samsung_AI_Center_Cambridge_UK_Guest_Talk_Invitation_Letter.pdf">(Invitation Letter)</A> <A href="https://14h034160212.github.io/Multi_Step_Deductive_Reasoning_Over_Natural_Language_An_Empirical_Study_on_Out_of_Distribution_Generalisation_Updated_Version_Samsung.pdf">(Presentation Slide)</A> <a href="https://youtu.be/0ZkayBD3WVY">(Recording)</a></li>
			<li>IEEE Vehicular Technology Society (VTS) New Zealand North Chapter and IEEE New Zealand North Section SIGHT Group 2022 <a href="https://14h034160212.github.io/IEEE_VTS_invited_talk.jpg">(Invitation Letter)</a> <a href="https://14h034160212.github.io/Qiming_Bao_IEEE_VTS_Natural_Language_Processing_Reasoning_Invited_Talk_Final.pdf">(Presentation Slide)</a> <a href="https://youtu.be/ZzCpq5gXQto">(Recording)</a></li>
			<li>NLP Group, The University of Melbourne Invited Talk 2023 <a href="https://14h034160212.github.io/Invitation_UoM_NLP_Reading_Group.pdf">(Invitation Letter)</a> <a href="https://14h034160212.github.io/University_of_Melbourne_Qiming_Bao_Invited_Talk_Natural_Language_Processing_and_Reasoning.pdf">(Presentation Slide)</a></li>
			<li>Institute of Automation, Chinese Academy of Sciences Invited Talk 2023 <a href="https://14h034160212.github.io/Invitation_UoM_NLP_Reading_Group.pdf">(Invitation Letter)</a> <a href="https://14h034160212.github.io/包启明-中国科学院自动化所“第一届紫东青年学者论坛分论坛：AI基础理论与创新应用”.pdf">(Presentation Slide)</a></li>
		</section>
    </div>
</body>
</html>
