
<HTML>
<HEAD>
<TITLE>
    Qiming (Bill) Bao's Publications
</TITLE>

<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="GENERATOR" content="Actual Drawing 7.1 (http://www.pysoft.com) [Unregistered]">
<style>
	a{
                text-decoration:none;
            }
</style>
</HEAD>

<BODY bgcolor="White" text="#000000" link="#0000FF" vlink="#800080"
    alink="#FF0000">

<div id="Layer4"





        style="position:absolute; left:37px; top:96px; width:1074px; height:706px; background-color:White; z-index:0">
		
		
    <p style="margin-left: 40px">

<FONT color=#800000 face="Bitstream Vera Sans">
	<p> See My <a href="https://www.researchgate.net/profile/Qiming_Bao2" target="blank">Researchgate</a> page</p>
	<br /> 2023 <br />
	[20 September 2023] Our paper (Qiming Bao, Juho Leinonen, Alex Yuxuan Peng, Wanjun Zhong, Tim Pistotti, Alice Huang, Paul Denny, Michael Witbrock and Jiamou Liu) <br /> "Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models" [<A href="http://arxiv.org/abs/2309.10444"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Explanation-Generation"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].<br/>
    <br />
	[24 June 2023] Our paper (Qiming Bao, Gaël Gendron, Alex Peng, Neset Tan, Michael Witbrock, Jiamou Liu)<br /> 
        "A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks" has been accepted by <A href="https://bigmodel.ai/llm-ijcai23"><FONT face="Bitstream Vera Sans">LLM@IJCAI'23</FONT></A><br />
    <br />
	[24 June 2023] Our paper (Qiming Bao, Alex Peng, Zhenyun Deng, Wanjun Zhong, Gaël Gendron, Neşet Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock and Jiamou Liu)<br /> 
        "Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation" has been accepted by <A href="https://bigmodel.ai/llm-ijcai23"><FONT face="Bitstream Vera Sans">LLM@IJCAI'23</FONT></A><br />
    <br />
	[31 May 2023] Our paper (Gaël Gendron, Qiming Bao, Michael Witbrock, Gillian Dobbie)<br /> 
        "Large Language Models Are Not Abstract Reasoners" [<A href="https://arxiv.org/abs/2305.19555"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning"><FONT face="Bitstream Vera Sans">Source code and evaluation platform</FONT></A>].<br />
        <br />
	[21 May 2023] Our paper (Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock, Jiamou Liu)<br /> 
        "Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text" [<A href="https://arxiv.org/abs/2305.12599"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>] [<A href="https://huggingface.co/qbao775/AMR-LE-DeBERTa-V2-XXLarge-Contraposition"><FONT face="Bitstream Vera Sans">Model weights</FONT></A>] [<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">#2 on the Leaderboard</FONT></A>].<br />
	<br />
	[10 April 2023] Our paper (Qianqian Qi, Qiming Bao*, Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock)<br /> 
        "A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge" has been accepted by <A href="https://openreview.net/group?id=ICLR.cc/2023/TinyPapers"><FONT face="Bitstream Vera Sans">ICLR 2023 TinyPapers</FONT></A> [<A href="https://openreview.net/forum?id=hli7A0ioiS_"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].<br />
    <br />
	[23 January 2023] Our paper (Neset Ozkan TAN, Trung Nguyen, Josh Bensemann, Alex Peng, Qiming Bao, Yang Chen, Mark Gahegan and Michael Witcbrock)<br /> 
        "Multi2Claim: Generating Scientific Claims from Multi-Choice Questions for Scientific Fact-Checking" has been accepted by <A href="https://2023.eacl.org/"><FONT face="Bitstream Vera Sans">EACL 2023</FONT></A> [<A href="https://aclanthology.org/2023.eacl-main.194/"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>]. 
	<br />
	<br />
	[11 December 2022] Our paper (Neset Tan, Alex Peng, Joshua Bensemann, Qiming Bao, Tim Hartill, Mark Gahegan, and Michael Witbrock)<br /> 
        "Input-length-shortening and text generation via attention values" has been accepted by <A href="https://www.emc2-ai.org/aaai-23"><FONT face="Bitstream Vera Sans">AAAI-EMC^2 2023</FONT></A> [<A href="https://arxiv.org/abs/2303.07585"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].
        <br />
	<br />
	<br /> 2022 <br />
	[19 December 2022] MSRA Invited Talk on Study Group on Reasoning, Knowledge, and Causality: Natural Language Processing and Reasoning <br />
        (Qiming Bao, Michael Witbrock, Jiamou Liu) <br />
        Microsoft Research Asia Invited Talk 2022 [<A href="./The University of Auckland Mail - Invited Talk_ Natural Language Processing and Reasoning (Study Group on Reasoning, Knowledge, and Causality).pdf"><FONT face="Bitstream Vera Sans">Invitation Letter</FONT></A>] <A href="./Invited Talk Natural Language Processing and Reasoning [Study Group on Reasoning, Knowledge, and Causality].pdf"><FONT face="Bitstream Vera Sans">[Presentation Slide]</FONT></A> [<A href="https://youtu.be/nfNbSZPY4EU"><FONT face="Bitstream Vera Sans">Recording</FONT></A>]
	<br />
	<br />
	[11 October 2022] Invited Talk: Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation (Qiming Bao, Alex Yuxuan Peng, Tim Hartill, Neşet Özkan Tan, Zhenyun Deng, Michael Witbrock, Jiamou Liu) <br />
	Samsung AI Center Cambridge UK Invited Talk 2022 [<A href="./Samsung_AI_Center_Cambridge_UK_Guest_Talk_Invitation_Letter.pdf"><FONT face="Bitstream Vera Sans">Invitation Letter</FONT></A>] <A href="./Multi_Step_Deductive_Reasoning_Over_Natural_Language_An_Empirical_Study_on_Out_of_Distribution_Generalisation_Updated_Version_Samsung.pdf"><FONT face="Bitstream Vera Sans">[Presentation slide]</FONT></A> [<A href="https://youtu.be/0ZkayBD3WVY"><FONT face="Bitstream Vera Sans">Recording</FONT></A>]
        <br />
	<br />
	[30 August 2022] Invited Talk: Natural Language Processing and Reasoning (Qiming Bao, Michael Witbrock, Jiamou Liu) <br />
	IEEE Vehicular Technology Society (VTS) New Zealand North Chapter and IEEE New Zealand North Section SIGHT Group 2022 [<A href="./IEEE_VTS_invited_talk.jpg"><FONT face="Bitstream Vera Sans">Invitation Letter</FONT></A>] [<A href="./Qiming_Bao_IEEE_VTS_Natural_Language_Processing_Reasoning_Invited_Talk_Final.pdf"><FONT face="Bitstream Vera Sans">Presentation slide</FONT></A>] [<A href="https://youtu.be/ZzCpq5gXQto"><FONT face="Bitstream Vera Sans">Recording</FONT></A>]
        <br />
	<br />
	[16 July 2022] Our paper (Qiming Bao, Alex Peng, Tim Hartill, Neset Tan, Zhenyun Deng, Michael Witbrock, Jiamou Liu) <br />
	"Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation" has been accepted for presentation to the <A href="http://ceur-ws.org/Vol-3212/"><FONT face="Bitstream Vera Sans">2nd International Joint Conference on Learning & Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning (IJCLR-NeSy 2022)</FONT></A> [<A href="https://www.cs.ox.ac.uk/isg/conferences/tmp-proceedings/NeSy2022/paper15.pdf"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language"><FONT face="Bitstream Vera Sans">Source code and dataset</FONT></A>] [<A href="http://ilp.doc.ic.ac.uk/ijclr22_videos/NeSy%20Session%205%20-%20Thursday%2029th%20-%2014_40%20-%2015_50%20(BST)%20includes%20NeSy%20Invited%20Talk%20William%20Cohen.mp4"><FONT face="Bitstream Vera Sans">Presentation recording</FONT></A>].
        <br />
	<br />
	[24 Feb 2022] Our paper (Nathan Young, Qiming Bao, Joshua Ljudo Bensemann, Michael J. Witbrock) "AbductionRules: Training Transformers to Explain Unexpected Inputs" has been accepted at <A href="https://www.2022.aclweb.org/"><FONT face="Bitstream Vera Sans">the Findings of 60th Annual Meeting of the Association for Computational Linguistics (ACL-22)</FONT></A> [<A href="https://aclanthology.org/2022.findings-acl.19/"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/AbductionRules"><FONT face="Bitstream Vera Sans">Source code and dataset</FONT></A>].
	<br /><br />
	<br /> 2021 <br />
	<br />
	[13 Nov 2021] Our paper (Lin Ni, Qiming Bao, Xiaoxuan Li, Qianqian Qi, Paul Denny, Jim Warren, Michael Witbrock and Jiamou Liu) "DeepQR: Neural-based Quality Ratings for Learnersourced Multiple-Choice Questions" has been accepted at <A href="https://aaai.org/Conferences/AAAI-22/eaai-22-call/"><FONT face="Bitstream Vera Sans">Twelfth AAAI Symposium on Educational Advances in Artificial Intelligence (AAAI/EAAI-22)</FONT></A> [<A href="https://ojs.aaai.org/index.php/AAAI/article/view/21562"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].
	<br /><br />
	[15 July 2021] Our paper (Joshua Bensemann, Qiming Bao, Gaël Gendron, Tim Hartill and Michael Witbrock)	"Relating Blindsight and AI: A Review" has been accepted at <A href="https://www.worldscientific.com/page/jaic/aims-scope"><FONT face="Bitstream Vera Sans">Journal of Artificial Intelligence and Consciousness</FONT></A> [<A href="https://doi.org/10.1142/S2705078521500156"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].
	<br /><br />
	[20 January 2021] Our poster (Qiming Bao, Michael Witbrock, Jiamou Liu) "From Symbolic Logic Reasoning to Soft Reasoning: A Neural-Symbolic Paradigm" has been accepted at <A href="https://www.ainz.ai/"><FONT face="Bitstream Vera Sans">New Zealand Workshop on Artificial Intelligence Research (NZAIR 2021)</FONT></A> [<A href="https://www.researchgate.net/publication/356695884_From_Symbolic_Logic_Reasoning_to_Soft_Reasoning_A_Neural-Symbolic_Paradigm"><FONT face="Bitstream Vera Sans">Poster link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/A-Neural-Symbolic-Paradigm"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].
	<br />
<br />
	
<br /> 2020 <br />
<br />
	[04 Feb 2020] Our paper (Qiming Bao, Lin Ni, Jiamou Liu) "HHH: An Online Medical Chatbot System based on Knowledge Graph and Hierarchical Bi-Directional Attention" has been accepted at <A href="http://www.acsw.org.au/"><FONT face="Bitstream Vera Sans">Australasian Computer Science Week (ACSW 2020)</FONT></A> [<A href="https://arxiv.org/abs/2002.03140"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/14H034160212/HHH-An-Online-Question-Answering-System-for-Medical-Questions"><FONT face="Bitstream Vera Sans">Source code</FONT></A>] [<A href="https://www.youtube.com/redirect?event=comments&redir_token=QUFFLUhqbWtqVHRmbzdQYVJFSW9odl9qZF9CWTdxUXdvQXxBQ3Jtc0ttQjRBdktkOFQ1enpvUGk1X0ZLT0hIb3g5WnhZWjVyVjFiVUQ1STdTeW9pMXdpYlJWSk9xeVA0Y01Qbm85bkQtRWxjdlk5TWdfY2I0OFNIazBhRkFoNEN6YmdjYTFaVnh3Ynkyel9LQjNhbkZ4WGxwQQ&q=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F15BfDM07IdUJiqONTAXAhIk3Y8a6oWn_2%2Fedit%3Fusp%3Dsharing%26ouid%3D116744487318855501460%26rtpof%3Dtrue%26sd%3Dtrue&stzid=UgxhkQ3dcho0vzjqWIV4AaABAg"><FONT face="Bitstream Vera Sans">Presentation slide</FONT></A>] [<A href="https://youtu.be/zTK3zZtxHs4"><FONT face="Bitstream Vera Sans">Recording</FONT></A>].<br />
<br />

	</p>
</div>

	<BR>


<div id="Layer1"
    style="position:absolute; left:37px; top:27px; width:508px; height:47px; background-color:#424242; z-index:1; margin-bottom: 1px;">
<FONT size=6 color=#F3F781 face="Bitstream Vera Sans"><B>&nbsp;Qiming Bao&#39;s
    Publications </B></FONT><BR>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-4914607-1");
pageTracker._initData();
pageTracker._trackPageview();
</script>
</FONT>
</BODY>
</HTML>
